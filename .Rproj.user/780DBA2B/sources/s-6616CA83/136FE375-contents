###########################################################################
## ocean_mesh.R
## Adapts program for Section 8.3 of Simpson et al. (2011)
## Author: Andrew Zammit Mangion
## This code comes with no warranty or guarantee of any kind.
###########################################################################

## Shapefiles obtained from https://www.ngdc.noaa.gov/mgg/shorelines/data/gshhg/latest/

##############################################
### Part 1: SETUP
##############################################
print("Part 1: Setting up...")

library(INLA)
library(Matrix)
library(sparseinv)
library(maptools)
library(dplyr)
library(data.table)
library(foreach)
library(doMC)
library(ggplot2)
library(dggrids)
library(spam)
require(verification)
library(LatticeKrig)
library(MVST)

setwd("~/Wollongong/GraphColouring/")
source("utils.R")

true.radius.of.earth = 6371
radius.of.earth = 1
hi_res_coastline <- 0
submeshes <- 1
sim_data <- 0
plot_figs <- 0
lo_res <- 0
INLA_lo_res <- 0
INLA_hi_res <- 0
LTK <- 0

sigma0 = 10
range0 = 0.3
kappa0 = sqrt(8/2)/range0
tau0 = 1/(sqrt(4*pi)*kappa0*sigma0)

sigma1 = 5
range1 = 0.03
kappa1 = sqrt(8/2)/range1
tau1 = 1/(sqrt(4*pi)*kappa1*sigma1)

cutoff <- ifelse(lo_res,200,100)
max.edge <- ifelse(lo_res,300,150)

md5_wrapper <- MVST::md5_cache(path = "~/cache/")


if(hi_res_coastline) {
    gshhg_path <- "~/Downloads/gshhg-shp-2.3.5/"
    coast_path <- file.path(gshhg_path,
                            "GSHHS_shp","h","GSHHS_h_L1.shp")
    antarctica_path <- file.path(gshhg_path,"GSHHS_shp","h","GSHHS_h_L5.shp")
    mesh <- md5_wrapper(fn=gen_ocean_mesh_hi_res,
                        coast_path=coast_path,
                        antarctica_path = antarctica_path,
                        print_output = TRUE)

} else {
    mesh <- gen_ocean_mesh_lo_res("australia.txt","antarctica.txt","eurasia_africa_americas.txt")
}

if(plot_figs) plot_3d_mesh(mesh)

if(sim_data) {
    ## Also simulate new mesh with no coastlines
    N <- 2000000
    print(paste0("N = ",N))
    set.seed(1)
    y_tot <- data.frame(lon = runif(N,min=-180,max=180),
                        lat=runif(N,min=-90,max=90))
    y_pred <- data.frame(lon = runif(N,min=-180,max=180),
                        lat=runif(N,min=-90,max=90))
    y_tot$n <- 1:nrow(y_tot)
    y_tot_design <- sample_n(y_tot,200000)
    mesh=inla.mesh.create(loc=lonlat3D(y_tot_design$lon,y_tot_design$lat),
                          cutoff=cutoff/true.radius.of.earth*1.5,
                          refine=list(max.edge=max.edge/true.radius.of.earth*1.5))
} else {
    load("SST_sub_1000000.rda")
    y_tot <- SST_sub_1000000 %>% filter(lat < 90) %>% distinct(lon,lat,.keep_all=TRUE) ## remove repetitions
    y_tot$lat2 <- y_tot$lat^2
    LM <- lm( sst ~ 1 + lat + lat2, data = y_tot)
    y_tot$z <- LM$residuals

    load("SST_sub_1000000_val.rda")
    y_pred <- SST_sub_1000000_val %>% filter(lat < 90) %>% distinct(lon,lat,.keep_all=TRUE)
    y_pred$lat2 <- y_pred$lat^2
    coeff <- LM$coefficients
    y_pred <- mutate(y_pred,z = sst - coeff[1] - coeff[2]*lat - coeff[3]*lat2)

    write.csv(y_tot,file="~/cache/y_tot.csv",row.names=FALSE)
    write.csv(y_pred,file="~/cache/y_pred.csv",row.names=FALSE)

}

spde <- inla.spde2.matern(mesh=mesh,alpha=2)
Qx = inla.spde.precision(spde, theta=c(log(tau0), log(kappa0)))
C0 <- inla.spde.make.A(mesh = mesh,loc=lonlat3D(y_tot$lon, y_tot$lat))
C0_pred <- inla.spde.make.A(mesh = mesh,loc=lonlat3D(y_pred$lon, y_pred$lat))

## Now filter those observations which fall outside triangles (bad data)
if(sim_data) {
    Qo <- 1/0.25*Diagonal(N)
} else {
    rm_idx <- which(rowSums(C0)==0)
    if(length(rm_idx) > 0) {
        y_tot <- y_tot[-rm_idx,]
        C0 <- C0[-rm_idx,]
    }
    Qo <- Diagonal(x=pmin(1/y_tot$error^2,10))

    # rm_idx <- which(rowSums(C0_pred)==0)
    # if(length(rm_idx) > 0) {
    #     y_pred <- y_pred[-rm_idx,]
    #     C0_pred <- C0_pred[-rm_idx,]
    # }

}


## Generate simulation data. Store in "z"
if(sim_data) {
    set.seed(1)
    x_true0 <- inla.qsample(Q = Qx) %>% as.numeric()
    y_tot$y <- (C0 %*% x_true0) %>% as.numeric()
    y_tot$z <- (y_tot$y + inla.qsample(Q = Qo)) %>% as.numeric()
    y_pred$y <- (C0_pred %*% x_true0) %>% as.numeric()
    y_pred$z <- (y_pred$y + inla.qsample(Q = Qo)) %>% as.numeric()
}


lo_res_world <- lo_res_mask("australia.txt","antarctica.txt","eurasia_africa_americas.txt")
mapWorld <- borders("world", colour="black", fill="light gray")

if(plot_figs) {
  g <- ggplot(y_tot[1:1000000,]) + geom_point(aes(lon,lat,colour=z),size=0.01) + nasa_scale("degC") + theme_bw() +
    geom_polygon(data=lo_res_world,aes(lon,lat,group=id),fill="light gray") +
    mapWorld + coord_fixed(xlim=c(-180,180),ratio=1.2)
  ggsave(g,file="SST1000000_data.png",width=16,height=10)

}


##################################################
### Part 2: OTHER INVERSIONS ONLY on LO RESOLUTION
##################################################
print("Part 2: Doing a straightforward inversion on low resolution...")
## Standard inversion with fixed realistic parameters
Qpost <- t(C0) %*% Qo %*% C0 + Qx
L <- cholPermute(Qpost)
mupost <- cholsolve(Qpost,t(C0) %*% Qo %*% y_tot$z,perm=T,
                          cholQp = L$Qpermchol, P = L$P) %>% as.numeric()
if(plot_figs) plot_map(mesh,mupost)

## Inversion using INLA with only low resolution
if(INLA_lo_res) {
    system.time({INLA_output <- INLA_spatial_estimation(spde,y_tot$z,C0,C0_pred)})
    save(INLA_output,file="~/cache/INLA_output.rda")
    project <- inla.mesh.projector(mesh,
                                   loc=lonlat3D(y_pred$lon,y_pred$lat))
    y_pred$spde_pred <-
      inla.mesh.project(project,INLA_output$summary.random$spatial.field$mean +
                                INLA_output$summary.fixed[1,1])

    y_pred$spde_se <-
      inla.mesh.project(project,sqrt(INLA_output$summary.random$spatial.field$sd^2 +
                                1/INLA_output$summary.hyperpar[1,1]))

    save(y_pred,file="~/cache/INLA_output_pred.rda")

    if(plot_figs) {
      g <- ggplot(y_pred) + geom_point(aes(lon,lat,colour=pmax(pmin(abs(z - spde_pred),1),-1)),
                                               size=0.01) +
        nasa_scale("degC") + theme_bw() +
        geom_polygon(data=lo_res_world,aes(lon,lat,group=id),fill="gray")
      ggsave(g,file="SST1000000_INLA_abserr.png",width=16,height=10)

    }
    stop()

  }

## Inversion using LTK with relatively low resolution
if(LTK) {
    # Takes about 30 minutes
    library(LatticeKrig)
    #LKinfo <- LKrigSetup(cbind(y_tot$lon,y_tot$lat),NC=100,nlevel=3,LKGeometry="LKRing")
    #domain<- cbind(c(-182,182),c(-90,90))
    #LKinfo <- LKrigSetup(NC=33,nlevel=3,nu=.5, a.wght=4.01,LKGeometry = "LKRing")
    #proc_time_LTK1 <- system.time({obj <- LatticeKrig(cbind(y_tot$lon,y_tot$lat), y_tot$z,LKinfo=LKinfo)})
    proc_time_LTK1 <- system.time({obj <- LatticeKrig(cbind(y_tot$lon,y_tot$lat), y_tot$z, NC = 100,
                                                      nlevel = 3, nu = 0.5, a.wght=4.01,LKGeometry="LKRing")})
    proc_time_LTK2 <- system.time({out.pred <- predict.LKrig(obj, xnew=cbind(y_pred$lon,y_pred$lat))})
    y_pred$LK_pred <- out.pred
    proc_time_LTK3 <- system.time({J <- LKrig.sim.conditional(obj, x.grid = as.matrix(y_pred[,1:2]),M=30)})
    y_pred$LK_se <- apply(J[[3]],1,sd)
    y_pred$LK_se_obs <- sqrt(y_pred$LK_se^2 + obj$sigma.MLE^2)
    save(y_pred,file="~/cache/LTK_output.rda")
    LK_results <- pred_results(y_pred$z,y_pred$LK_pred,y_pred$LK_se_obs)
    stop()
}

###########################################################
### Part 3: Setting up the partitions and finer resolutions
###########################################################
print("Part 3: Setting up finer resolutions...")
lat_mesh = asin(mesh$loc[,3])*360/(2*pi)
lon_mesh = atan2(mesh$loc[,2], mesh$loc[,1])*360/(2*pi)
df_mesh <- data.frame(lat=lat_mesh,lon=lon_mesh)

## Now find neighbours on graph
mesh_nei2 <- neighb_from_prec2(mesh$graph$vv)

## Now find points on graph
points <- df_mesh[,c("lon","lat")]
names(points) <- c("x","y")
points$id <- 1:nrow(points)

## Partition points
data("isea3h")
isea3h_centroids <- filter(isea3h,centroid==1 & res==ifelse(sim_data,2,3))

## Two rules: Don't let patches have too few triangles and
## don't let patches have too few data points
min_obs <- 300
min_tri <- 200
OK_triangles <- OK_data <-  0
while(!(OK_triangles & OK_data)) {
    D <- fields::rdist.earth(df_mesh[,c("lon","lat")],
                             isea3h_centroids[,c("lon","lat")])
    points$class <- apply(D,1,function(x) which.min(x))

    ## Too few triangles?
    if(all(table(points$class) >= min_tri)) {
        OK_triangles <- 1
        ## Too few data points?
        obs_class <- points %>% group_by(class) %>%
            summarise(obsability = sum(C0[,id]))
        if(all(obs_class$obsability >= 100)) {OK_data <- 1}
        else {
            OK_data <- 0
            rm_basis <- which(obs_class$obsability < 100)
            isea3h_centroids <- isea3h_centroids[-rm_basis,]
        }
    } else {
        OK_triangles <- 0
        rm_basis <- which(table(points$class) < min_tri)
        isea3h_centroids <- isea3h_centroids[-rm_basis,]
    }
}


## Relabel as 1,2,3... as may not be contiguous
nchunks <- length(unique(points$class))
relabel <- data.frame(newclass = 1:nchunks,
                      class = unique(points$class))
points <- left_join(points,relabel) %>%
    mutate(class=newclass) %>%
    dplyr::select(-newclass)

partition_nei_list <- partition_nei_from_points(points,mesh_nei2)
adj.matrix <- adj_matrix_from_nei_list(partition_nei_list)
if(plot_figs) plot_map(mesh,points$class)

partition_colour <- colour_graph(adj.matrix,
                                 method="backtrack",
                                 numcolours=30,startnode=2,obs=NULL)
hulls <- plyr::ddply(points, "class", find_hull)
hulls$colour <- NULL
hulls <- merge(hulls,partition_colour,by="class")
points <- merge(points,partition_colour,by="class")
points <- points[order(points$id),]

### Plot graph colourings
stopifnot(length(unique(partition_colour$colour)) == 4)
if(plot_figs) {
   g <- plot_map(mesh,points$colour)
   ggsave(g,file="SSTcolouring2.png",width=16,height=10)
}

### Now get the hulls and create other meshes inside them by going into 3D space.
### For the data generation I only use meshes that are enclosed exactly by the meshes
# if(submeshes)
#     sub_meshes <- lapply(unique(points$class),
#                               function(cl) {
#                                   this_hull <- filter(points,class==cl)
#                                   bndary <- find_border_from_points(this_hull[,c("x","y")])
#                                   coords3d <- lonlat3D(bndary[,1],bndary[,2])
#                                   this_seg <- inla.mesh.segment(loc=coords3d)
#                                   print(cl)
#                                   inla.mesh.create(boundary = this_seg,
#                                                    cutoff=25/6371,
#                                                    refine=list(max.edge=45/6371))
#                               })

## For modelling I use meshes with some buffer
## Don't let each submesh contain more than 35000 triangles
print("...Constructing sub-meshes with buffers...")

if(submeshes)
    sub_meshes_ext <- lapply(unique(points$class),
                                  function(cl) {
                                      max.edge.sub <- 35/6371
                                      this_hull <- filter(points,class==cl)
                                      coords3d <- lonlat3D(this_hull[,"x"],this_hull[,"y"])
                                      print(cl)
                                      OK <- FALSE
                                      while(!OK) {
                                         sub_mesh <- inla.mesh.create(loc =  coords3d,
                                                                      cutoff=15/6371,  #25
                                                                      refine=list(max.edge=max.edge.sub))  #45
                                         if(sub_mesh$n < 35000) OK <- 1
                                         max.edge.sub <- max.edge.sub*1.1
                                      }
                                      sub_mesh
                                  })

max.edge <- 75
mesh_fine <- gen_ocean_mesh_lo_res("australia.txt","antarctica.txt","eurasia_africa_americas.txt")
  
  inla.mesh.create(loc = coords3d,
                              cutoff=15/6371,  #25
                              refine=list(max.edge=max.edge.sub))  #45

if(plot_figs) {
    plot_3d_mesh(mesh,col="white")
    for(i in 1:length(sub_meshes_ext))
        plot_3d_mesh(sub_meshes_ext[[i]],new_window = FALSE,col="yellow")
}

Q_full <- Qx
x_prior <- matrix(rep(0,nrow(Q_full)))
C_full <- C0
x_des <- points
x_des$id <- x_des$id
Qobs <- Qo
x_des$n <- 1:nrow(x_des)
x_des$prior <- 0
x_des$mean <- x_des$prior

x_des$block <- x_des$class
x_des$wave <- x_des$colour
bl_list <- sort(unique(x_des$block))
numblocks <- length(bl_list)
ib <- X <- L <- Q <- vector("list",numblocks)

for (i in 1:numblocks) ib[[i]] <-  which(x_des$block==bl_list[i])
block_wave_map <- as.data.frame(unique(cbind(x_des$block,x_des$wave)))
names(block_wave_map) <- c("block","wave")

## Allocate observations to the sub-meshes
print("...Seeing in which blocks observations fall...")
if(submeshes) {
    C0_dgT <- as(C0,"dgTMatrix")
    C0_long <- data.frame(i = C0_dgT@i+1,j= C0_dgT@j+1,x = C0_dgT@x)
    obs_alloc <- group_by(C0_long,i) %>% dplyr::summarise(lxsens = j[which.max(x)])
    y_tot$cl2 <- points[obs_alloc$lxsens,]$class

    rm_idx <- which(rowSums(C0_pred) == 0)
    C0_pred <- C0_pred[-rm_idx,]
    y_pred <- y_pred[-rm_idx,]
    C0_pred_dgT <- as(C0_pred,"dgTMatrix")
    C0_pred_long <- data.frame(i = C0_pred_dgT@i+1,j= C0_pred_dgT@j+1,x = C0_pred_dgT@x)
    val_alloc <- group_by(C0_pred_long,i) %>% dplyr::summarise(lxsens = j[which.max(x)])
    y_pred$cl2 <- points[val_alloc$lxsens,]$class

}

# Simulate
if(submeshes & sim_data) if(1) {
    print("...Simulating data on the submeshes...")
    z_all <- y_tot$z
    x_true1 <- list()
    for(i in 1:length(sub_meshes_ext)) {
        spde1 <- inla.spde2.matern(mesh=sub_meshes_ext[[i]],alpha=2)
        Q1 <- inla.spde.precision(spde1, theta=c(log(tau1),
                                                 log(kappa1)))
        x_true1[[i]] <- inla.qsample(Q = Q1) %>% as.numeric()

        affected_obs <- which(y_tot$cl ==i)
        y_tot_sub <- y_tot[affected_obs,]
        C1_full <- inla.spde.make.A(mesh = sub_meshes_ext[[i]],
                                    loc=lonlat3D(y_tot_sub$lon,
                                                 y_tot_sub$lat))
        y_true1 <- C1_full %*% x_true1[[i]] %>% as.numeric()
        z_all[affected_obs] <- z_all[affected_obs] + y_true1
        print(i)
    }
    y_tot$z <- as.numeric(z_all) ## This is our data
    save(y_tot,file="~/cache/y_tot.rda")
}
if(submeshes & sim_data)  load("~/cache/y_tot.rda")


##############################################
### Part 5: Distributing components into chunks
##############################################
print("Part 5: Distributing components into chunks")
chunks <- lapply(unique(points$class), function(cl) {
    cat(paste0(cl," "))
    ### NOW LET'S CHUNK UP THE DATA ASWELL
    ### When we do a chunk, we need the data for that chunk
    X <- filter(points, class==cl)
    ## we definitely need those observations which  affect these states
    keep_id <- X$id
    ## We need those states in X, but also those states that are affected
    ## by the border observations. We find these border "states"
    ## by first finding the observations we need
    obs_in_chunk <- which(rowSums(C0[,(keep_id)]) > 0)
    ## and then seeing what states these affect
    affected_states <- which(colSums(C0[obs_in_chunk,]) > 0)
    ## and then finding the union
    considered_states <- union(affected_states,keep_id)
    complementary_states <- setdiff(considered_states,keep_id)

    g <- ggplot(x_des[keep_id,])  +
        geom_point(aes(x,y),colour="black") +
        geom_point(data=x_des[complementary_states,],aes(x,y),colour="red")
    C0_in <- C0[obs_in_chunk,keep_id]
    C0_out <- C0[obs_in_chunk,complementary_states]
    z01 <- y_tot$z[obs_in_chunk]

    ### Find all neighbours (these should include all the complementary states)
    Qtemp <- as(Qx[keep_id, ],"dgTMatrix")
    all_neighb <- setdiff(unique(Qtemp@j) + 1, keep_id)

    ## For modelling we use the extended meshes
    if(submeshes) {
        spde1 <- inla.spde2.matern(mesh = sub_meshes_ext[[cl]], alpha=2)
        Q1 <- inla.spde.precision(spde1, theta=c(log(tau1),
                                                 log(kappa1)))
        
        ## Create the incidence matrix mapping observations to vertex locations
        C1 <- inla.spde.make.A(mesh = sub_meshes_ext[[cl]],
                               loc = lonlat3D(y_tot$lon[obs_in_chunk],
                                            y_tot$lat[obs_in_chunk]))

        ## NEXT: Zero out the rows in C1 corresponding to observations that
        ## are affected by fine-scale variation of neighbouring class
        C1_to_zero <- which(!(y_tot[obs_in_chunk,]$cl2 == cl))
        C1[C1_to_zero,] <- 0

        ## Now find the C matrices of all the neighbours for the border data points
        # (Essentially assume that data only affect the fine-scale process IN that chunk)
        neighb_facets <- setdiff(unique(y_tot[obs_in_chunk,]$cl2),cl)
        Neighb_C <- lapply(neighb_facets, function(neighb_cl) {
            C1_neighb_cl <- inla.spde.make.A(mesh = sub_meshes_ext[[neighb_cl]],
                                      loc = lonlat3D(y_tot$lon[obs_in_chunk],
                                                     y_tot$lat[obs_in_chunk]))
            C1_neighb_cl_to_zero <- which(!(y_tot[obs_in_chunk,]$cl2 == neighb_cl))
            C1_neighb_cl[C1_neighb_cl_to_zero,] <- 0
            C1_neighb_cl
        })
        names(Neighb_C) <- neighb_facets

        ## For quick construction of Q
        P <- sparseinv:::.amd_Davis(Q1)
        Mall_df <- elements_in_df(spde1)
        QC <- as(spde1$param.inla$M2,"dgCMatrix") ## symbolic dgCMatrix

        C_allj <- cbind(C0_in, C1)
        Qj_in <- bdiag(Qx[keep_id, keep_id],Q1)
        Qtildejj2 <- t(C_allj) %*%  Qobs[obs_in_chunk,obs_in_chunk] %*% C_allj + Qj_in
        Ppost <- sparseinv:::.amd_Davis(Qtildejj2)

    } else {
        spde1 <- Q1 <- C1 <- Neighb_C <- P <- Mall_df <- QC <- NULL
    }

    list(C0_in = C0_in, C0_out = C0_out,
         obs_idx = obs_in_chunk,
         z = z01, in_idx = keep_id, nei_idx = all_neighb,
         Qobs = Qobs[obs_in_chunk,obs_in_chunk],
         out_idx = complementary_states,
         all_idx = considered_states,g=g,
         spde1 = spde1, Q1 = Q1, C1 = C1,
         Neighb_C = Neighb_C, P = P, Ppost = Ppost,
         Mall_df = Mall_df, QC = QC)
})

## Do INLA on the individual blocks

stop()
if(INLA_hi_res) {
   for (i in 1:length(chunks)) {
    print(paste0("INLA fine res: Doing chunk ",i))
    ch <- chunks[[i]]
    this_mean <- mean(ch$z) ## detrend mean manually to make INLA faster and not estimate mean
    new_spde <- inla.spde2.matern(mesh=sub_meshes_ext[[i]],alpha=1)
    system.time({INLA_output_hi <- INLA_spatial_estimation2(new_spde, #ch$spde1, # no mean estimation
                                                        ch$z - mean(ch$z),
                                                        ch$C1)})
    sub_mesh <- sub_meshes_ext[[i]]
    save(INLA_output_hi,sub_mesh,
         file=paste0("~/cache/INLA_output_hi",i,".rda"))

    y_pred_i <- filter(y_pred,cl2==i)
    project <- inla.mesh.projector(sub_mesh,
                                   loc=lonlat3D(y_pred_i$lon,y_pred_i$lat))
    y_pred_i$spde_pred_hi <-
      inla.mesh.project(project,INLA_output_hi$summary.random$spatial.field$mean +
                                this_mean)

    y_pred_i$spde_se_hi <-
      inla.mesh.project(project,sqrt(INLA_output_hi$summary.random$spatial.field$sd^2 +
                                     1/INLA_output_hi$summary.hyperpar[1,1]))

    coverage90(y_pred_i$z,y_pred_i$spde_pred_hi,y_pred_i$spde_se_hi)
    if(i==1) {
        y_pred_temp <- y_pred_i
    } else {
        y_pred_temp <- rbind(y_pred_temp,y_pred_i)
    }
   }
   save(y_pred_temp,file="~/cache/INLA_output_hi_pred.rda")
   stop()
}



## Save the individual chunks to disk and not compressing for fast load
print("...Saving individual chunks to disk...")
sapply(1:length(chunks),function(i) {
    ch <- chunks[[i]]
    save(ch,file=paste0("~/cache/chunks",i,".rda"),
         compress=FALSE)})


if(submeshes & sim_data & plot_figs) {
    base_map <- plot_map(mesh,x_true0,plot=FALSE)
    for(i in 1:length(chunks)) {
        proj <- inla.mesh.projector(sub_meshes[[i]], dims=c(3*361,3*181))
        zproj <- inla.mesh.project(proj, field=as.numeric(x_true1[[i]]))
        zproj_vec <- reshape2::melt(zproj)[,3]
        zproj_vec[!is.na(base_map$grid_data$z) & is.na(zproj_vec)] <- 0
        base_map$grid_data$z <- rowSums(cbind(base_map$grid_data$z,
                                              zproj_vec))
    }
    print(ggplot(base_map$grid_data) +
              geom_tile(aes(lon,lat,fill=z)) +
              scale_fill_distiller(palette="Spectral"))
}

nchunks <- length(chunks)
zmean_df <- data.frame(class = 1:nchunks,
                       zmean = sapply(chunks,function(l) mean(l$z)))
x_samp0_init <- left_join(x_des,zmean_df)$zmean
if(submeshes) current_xsamp1 <- lapply(1:nchunks,function(i) rep(0,ncol(chunks[[i]]$C1))) else current_xsamp1 <- NULL

print("...Saving chunks and information for HPC sampling...")
if(1) save(x_des,mesh,spde,Q_full,block_wave_map,current_xsamp1,x_samp0_init,
           tau0,kappa0,tau1,kappa1,file="~/cache/data_for_SST2M_no_chunks.rda")

##############################################
### Part 6: Sampling
##############################################
# From here on run on the HPC
# Can be run independently from all of the above
source("ocean_sampling.R")
